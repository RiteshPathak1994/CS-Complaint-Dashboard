# full_app.py - Complete Professional Version (enhanced monthly report)
import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime, timedelta
import pytz
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import os
from dotenv import load_dotenv
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io
import plotly.express as px
from streamlit_option_menu import option_menu
import calendar
import time

# ----------------------------
# CONFIG
# ----------------------------
IMPL_SPREADSHEET_NAME = "Master Implementation sheet"
IMPL_TAB_NAME = "CS Team"

COMPLAINT_SPREADSHEET_NAME = "CS Comp"
COMPLAINT_TAB_NAME = "Comp"

REPORTER_SHEET_URL = "https://docs.google.com/spreadsheets/d/1OJWpQOwevw1W5iNUk6dm_wfZphuBdjboCkrQwYwTNOY/edit#gid=0"

ADMIN_EMAIL = os.getenv("ADMIN_EMAIL", "your_email@gmail.com")
MANAGER_EMAIL = os.getenv("MANAGER_EMAIL", "manager_email@gmail.com")
DRIVE_FOLDER_ID = "12s1H0gbboQo-Ha_d86Miack9QvX6wHde"   # complaint attachments folder

# ----------------------------
# AUTH
# ----------------------------
@st.cache_resource
def get_gspread_client():
    scope = ["https://www.googleapis.com/auth/spreadsheets",
             "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file("service_account.json", scopes=scope)
    return gspread.authorize(creds)

client = get_gspread_client()

def get_drive_service():
    scope = ["https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file("service_account.json", scopes=scope)
    return build("drive", "v3", credentials=creds)

# ----------------------------
# EMAIL HELPER
# ----------------------------
load_dotenv()

def send_email_with_attachments(to_emails, subject, body, attachments=None):
    """
    to_emails: list or comma-separated string
    attachments: list of dicts: {"filename": "report.csv", "content": bytes, "mimetype": "text/csv"}
    """
    if isinstance(to_emails, str):
        to_emails = [e.strip() for e in to_emails.split(",") if e.strip()]
    sender_email = os.getenv("EMAIL_USER")
    sender_password = os.getenv("EMAIL_PASS")
    if not sender_email or not sender_password:
        st.error("Email credentials not set (EMAIL_USER / EMAIL_PASS). Cannot send email.")
        return False, "Email credentials not configured"
    msg = MIMEMultipart()
    msg["From"] = sender_email
    msg["To"] = ", ".join(to_emails)
    msg["Subject"] = subject
    msg.attach(MIMEText(body, "plain"))

    # attach files
    if attachments:
        for att in attachments:
            filename = att.get("filename", "attachment")
            content = att.get("content", b"")
            mimetype = att.get("mimetype", "application/octet-stream")
            part = MIMEBase("application", "octet-stream")
            part.set_payload(content)
            encoders.encode_base64(part)
            part.add_header("Content-Disposition", f'attachment; filename="{filename}"')
            msg.attach(part)

    try:
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(sender_email, sender_password)
        server.sendmail(sender_email, to_emails, msg.as_string())
        server.quit()
        return True, None
    except Exception as e:
        return False, str(e)

def get_reporter_email(reporter_name):
    try:
        reporter_ss = client.open_by_url(REPORTER_SHEET_URL)
        reporter_ws = reporter_ss.get_worksheet(0)
        records = reporter_ws.get_all_records()
        for row in records:
            if str(row.get("Reporter Name", "")).strip().lower() == reporter_name.strip().lower():
                return row.get("Email Address")
    except Exception:
        return None
    return None

# ----------------------------
# HELPERS
# ----------------------------
@st.cache_data(ttl=300)
def load_school_names():
    impl_ss = client.open(IMPL_SPREADSHEET_NAME)
    impl_ws = impl_ss.worksheet(IMPL_TAB_NAME)
    values = impl_ws.get_all_values()
    if not values:
        return []
    header = [h.strip() for h in values[0]]
    rows = values[1:]
    school_col_idx = next((i for i, h in enumerate(header) if "school" in h.lower()), 0)
    schools = [r[school_col_idx].strip() for r in rows if len(r) > school_col_idx and r[school_col_idx].strip()]
    return list(dict.fromkeys(schools))  # unique

def append_complaint_row(row):
    comp_ss = client.open(COMPLAINT_SPREADSHEET_NAME)
    comp_ws = comp_ss.worksheet(COMPLAINT_TAB_NAME)
    comp_ws.append_row(row)

def get_ist_timestamp():
    tz = pytz.timezone("Asia/Kolkata")
    return datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

@st.cache_data(ttl=120)
def fetch_recent_complaints(limit=5000):
    comp_ss = client.open(COMPLAINT_SPREADSHEET_NAME)
    comp_ws = comp_ss.worksheet(COMPLAINT_TAB_NAME)
    records = comp_ws.get_all_records()
    if not records:
        return pd.DataFrame()
    return pd.DataFrame(records).tail(limit)

def upload_to_drive(file):
    if not file:
        return ""
    drive_service = get_drive_service()
    file_metadata = {"name": file.name, "parents": [DRIVE_FOLDER_ID]}
    media = MediaIoBaseUpload(io.BytesIO(file.getvalue()), mimetype=file.type)
    uploaded = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    file_id = uploaded.get("id")
    drive_service.permissions().create(fileId=file_id, body={"type": "anyone", "role": "reader"}).execute()
    return f"https://drive.google.com/file/d/{file_id}/view?usp=sharing"

# ----------------------------
# FIXED: Implementation Data Loader (handles duplicate headers)
# ----------------------------
@st.cache_data(ttl=300)
def load_implementation_data():
    impl_ss = client.open(IMPL_SPREADSHEET_NAME)
    impl_ws = impl_ss.worksheet(IMPL_TAB_NAME)
    values = impl_ws.get_all_values()
    if not values:
        return pd.DataFrame()
    headers = values[0]
    seen, fixed_headers = {}, []
    for h in headers:
        h = h.strip()
        if h in seen:
            seen[h] += 1
            fixed_headers.append(f"{h}_{seen[h]}")
        else:
            seen[h] = 1
            fixed_headers.append(h)
    rows = values[1:]
    df = pd.DataFrame(rows, columns=fixed_headers)
    # normalize whitespace in column names
    df.columns = [c.strip() for c in df.columns]
    return df

# ----------------------------
# Utility: find a column name by keyword(s)
# ----------------------------
def find_col(df, keywords):
    """Return first column from df.columns that contains any of keywords (case-insensitive)."""
    if df is None or df.columns.empty:
        return None
    cols = list(df.columns)
    for kw in keywords:
        for c in cols:
            if kw.lower() in str(c).lower():
                return c
    return None

def find_cols(df, keywords_list):
    """Return list of matching columns for any of keywords_list (any match)."""
    res = []
    if df is None or df.columns.empty:
        return res
    cols = list(df.columns)
    for c in cols:
        lc = str(c).lower()
        for kw in keywords_list:
            if kw.lower() in lc:
                res.append(c)
                break
    return res

def is_completed_value(v):
    if pd.isna(v):
        return False
    s = str(v).strip().lower()
    return any(x in s for x in ["complete", "completed", "done", "yes", "y"])

# ----------------------------
# MONTHLY REPORT BUILDER
# ----------------------------
def parse_dates_series(series):
    return pd.to_datetime(series, errors="coerce", infer_datetime_format=True)

def build_monthly_report(df_all, year:int, month:int):
    """
    df_all: DataFrame with complaints (raw)
    year, month: ints
    returns: dict with report summary, csv bytes for attachment
    """
    report = {}
    # defensive column names
    ts_col = find_col(df_all, ["timestamp", "time", "created"])
    status_col = find_col(df_all, ["status"])
    cat_col = find_col(df_all, ["category", "issue", "type"])
    school_col = find_col(df_all, ["school", "institution", "organisation", "organization"])
    severity_col = find_col(df_all, ["priority", "severity"])
    closed_ts_col = find_col(df_all, ["closed", "resolved", "closed timestamp", "resolved timestamp", "closed_at", "resolved_at"])

    # Parse timestamp column
    if ts_col:
        df_all["_ts"] = parse_dates_series(df_all[ts_col])
    else:
        df_all["_ts"] = pd.NaT

    # filter by requested month
    start = pd.Timestamp(year=year, month=month, day=1)
    last_day = calendar.monthrange(year, month)[1]
    end = pd.Timestamp(year=year, month=month, day=last_day) + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)
    df_month = df_all[(df_all["_ts"].notna()) & (df_all["_ts"] >= start) & (df_all["_ts"] <= end)].copy()

    report['year'] = year
    report['month'] = month
    report['total'] = int(len(df_month))

    # status breakdown
    if status_col:
        df_month["_status_norm"] = df_month[status_col].astype(str).str.strip().str.lower()
        def label_status(s):
            s = str(s).strip().lower()
            if "open" in s:
                return "Open"
            if "progress" in s or "in progress" in s:
                return "In Progress"
            if "close" in s or "closed" in s or "resolved" in s:
                return "Closed"
            return s.title() if s else "Unknown"
        status_counts = df_month["_status_norm"].apply(label_status).value_counts().to_dict()
    else:
        status_counts = {}

    report['status_counts'] = {k: int(v) for k,v in status_counts.items()}

    # top categories
    if cat_col and not df_month.empty:
        top_cats = df_month[cat_col].astype(str).str.strip().replace("", "Unknown").value_counts().head(5).to_dict()
    else:
        top_cats = {}
    report['top_categories'] = {k: int(v) for k,v in top_cats.items()}

    # top schools
    if school_col and not df_month.empty:
        top_schools = df_month[school_col].astype(str).str.strip().replace("", "Unknown").value_counts().head(5).to_dict()
    else:
        top_schools = {}
    report['top_schools'] = {k: int(v) for k,v in top_schools.items()}

    # severity counts
    if severity_col and not df_month.empty:
        sev = df_month[severity_col].astype(str).str.strip().str.title().replace("", "Unknown").value_counts().to_dict()
    else:
        sev = {}
    report['severity_counts'] = {k: int(v) for k,v in sev.items()}

    # average time to close (if closed timestamp present)
    avg_close_hours = None
    if closed_ts_col and not df_month.empty:
        df_month["_closed_ts"] = parse_dates_series(df_month[closed_ts_col])
        # only where both ts and closed exist and closed >= ts
        valid = df_month[(df_month["_ts"].notna()) & (df_month["_closed_ts"].notna())]
        if not valid.empty:
            diffs = (valid["_closed_ts"] - valid["_ts"]).dt.total_seconds() / 3600.0
            diffs = diffs[diffs >= 0]  # ignore negative
            if not diffs.empty:
                avg_close_hours = round(float(diffs.mean()), 2)
    report['avg_close_hours'] = avg_close_hours

    # prepare CSV attachment of monthly complaints
    csv_bytes = None
    if not df_month.empty:
        # Keep meaningful columns for CSV: ts_col, status, cat, school, severity, attachment
        keep_cols = []
        for c in [ts_col, status_col, cat_col, school_col, severity_col, closed_ts_col]:
            if c:
                keep_cols.append(c)
        # fallback to sending all columns
        export_df = df_month.copy()
        if keep_cols:
            # ensure keep cols are present
            export_cols = [c for c in keep_cols if c in export_df.columns]
            # also include everything else to be safe
            export_df = export_df[export_cols + [c for c in export_df.columns if c not in export_cols]]
        csv_bytes = export_df.to_csv(index=False).encode("utf-8")

    return report, csv_bytes

def format_report_text(report):
    ym = f"{report['month']:02d}/{report['year']}"
    lines = [f"Monthly Complaint Report - {ym}", ""]
    lines.append(f"Total Complaints: {report.get('total', 0)}")
    sc = report.get('status_counts', {})
    if sc:
        lines.append("Status counts:")
        for k,v in sc.items():
            lines.append(f"  ‚Ä¢ {k}: {v}")
    tc = report.get('top_categories', {})
    if tc:
        lines.append("Top Categories:")
        for k,v in tc.items():
            lines.append(f"  ‚Ä¢ {k}: {v}")
    ts = report.get('top_schools', {})
    if ts:
        lines.append("Top Schools:")
        for k,v in ts.items():
            lines.append(f"  ‚Ä¢ {k}: {v}")
    sev = report.get('severity_counts', {})
    if sev:
        lines.append("Severity:")
        for k,v in sev.items():
            lines.append(f"  ‚Ä¢ {k}: {v}")
    avg_close = report.get('avg_close_hours')
    if avg_close is not None:
        lines.append(f"Average time to close: {avg_close} hours")
    lines.append("")
    lines.append("Regards,\nCS Dashboard")
    return "\n".join(lines)

# ----------------------------
# PAGE NAVIGATION (CLASSY LIGHT NAVBAR)
# ----------------------------
st.set_page_config(page_title="CS App", page_icon="üìù", layout="wide")

selected = option_menu(
    menu_title="",
    options=["Complaints Dashboard", "Implementation Monitoring"],
    icons=["exclamation-circle", "bar-chart"],
    orientation="horizontal",
    styles={
        "container": {"padding": "6px", "background-color": "#f8fafc", "border-bottom": "1px solid #e6edf3"},
        "icon": {"color": "#0b5ed7", "font-size": "18px"},
        "nav-link": {"font-size": "15px", "text-align": "center", "margin": "0 6px", "color": "#0f172a"},
        "nav-link-selected": {"background-color": "#0b5ed7", "color": "white", "font-weight": "600"},
    }
)

# ----------------------------
# PAGE 1: COMPLAINT DASHBOARD
# ----------------------------
if selected == "Complaints Dashboard":
    st.title("üìù CS Complaint Dashboard")

    st.sidebar.header("‚öôÔ∏è Complaint Controls")
    if st.sidebar.button("üîÑ Refresh complaints"):
        # Clear cached data then attempt to rerun; if rerun not available, force reload via query params
        st.cache_data.clear()
        try:
            st.experimental_rerun()
        except Exception:
            # fallback - update st.query_params (new style) to force Streamlit to reload
            # assign a new dict including a timestamp to make the query params change
            params = dict(st.query_params) if hasattr(st, "query_params") else {}
            params["_refresh"] = str(int(time.time()))
            st.query_params = params

    # Month selector for monthly report (defaults to current month)
    today = pd.Timestamp.now(tz=pytz.timezone("Asia/Kolkata"))
    sel_year = st.sidebar.selectbox("Report Year", options=list(range(today.year-2, today.year+1)), index=2)
    months = [calendar.month_name[i] for i in range(1,13)]
    sel_month_idx = st.sidebar.selectbox("Report Month", options=list(range(1,13)), index=today.month-1)
    # Note: sel_month_idx is 1..12

    if st.sidebar.button("üìß Send Monthly Report"):
        df_all = fetch_recent_complaints(limit=5000)
        if df_all.empty:
            st.warning("No complaints data available to send report.")
        else:
            with st.spinner("Building monthly report..."):
                report, csv_bytes = build_monthly_report(df_all, sel_year, sel_month_idx)
                body = format_report_text(report)
                attachments = []
                if csv_bytes:
                    attachments.append({"filename": f"complaints_{sel_year}_{sel_month_idx:02d}.csv", "content": csv_bytes, "mimetype": "text/csv"})
                # send to admin and manager
                to_list = [ADMIN_EMAIL, MANAGER_EMAIL]
                ok, err = send_email_with_attachments(to_list, f"üìä Monthly Complaints Report - {sel_month_idx:02d}/{sel_year}", body, attachments=attachments)
                if ok:
                    st.success("‚úÖ Monthly report sent to you and your manager!")
                else:
                    st.error(f"Failed to send monthly report: {err}")

    status_filter = st.sidebar.selectbox("Filter by Status", ["All", "Open", "In Progress", "Closed"], index=0)

    # KPI DASHBOARD
    df_all = fetch_recent_complaints(limit=5000)
    if df_all.empty:
        st.info("‚ÑπÔ∏è No complaints data available yet.")
    else:
        total_complaints = len(df_all)
        if "Status" in df_all.columns:
            open_count = df_all[df_all["Status"].astype(str).str.strip().str.lower() == "open"].shape[0]
        else:
            open_count = 0
        open_percent = round((open_count / total_complaints) * 100, 1) if total_complaints else 0
        if "Timestamp" in df_all.columns:
            df_all["Timestamp"] = pd.to_datetime(df_all["Timestamp"], errors="coerce")
            this_month = df_all[df_all["Timestamp"].dt.to_period("M") == pd.Timestamp.now().to_period("M")]
        else:
            df_all["Timestamp"] = pd.Series(pd.to_datetime([], errors="coerce"))
            this_month = pd.DataFrame()
        top_category = this_month["Category"].value_counts().idxmax() if ("Category" in df_all.columns and not this_month.empty) else "N/A"
        c1, c2, c3 = st.columns(3)
        c1.metric("üìå Total Complaints", total_complaints)
        c2.metric("üü† Open %", f"{open_percent}%")
        c3.metric("üèÜ Top Category", top_category)

    st.markdown("---")

    # PROFESSIONAL COMPLAINT FORM
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 1rem; border-radius: 12px; margin: 1rem 0;">
        <h3 style="color: white; text-align: center; margin: 0; font-weight: 600;">
            üìù Submit New Complaint
        </h3>
        <p style="color: rgba(255,255,255,0.9); text-align: center; margin: 0.5rem 0 0 0; font-size: 0.9rem;">
            Please provide detailed information to help us resolve your concern efficiently
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Main form container with professional styling
    with st.container():
        st.markdown("""
        <style>
        .complaint-form {
            background: white;
            border-radius: 16px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            border: 1px solid #e5e7eb;
            padding: 2rem;
            margin: 1rem 0;
        }
        .form-section {
            margin-bottom: 1.5rem;
        }
        .section-header {
            color: #374151;
            font-size: 1.1rem;
            font-weight: 600;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e5e7eb;
        }
        .required-field {
            color: #dc2626;
            font-weight: bold;
            font-size: 0.8rem;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Form wrapper
        st.markdown('<div class="complaint-form">', unsafe_allow_html=True)
        
        with st.form("complaint_form", clear_on_submit=True):
            # Reporter Information Section
            st.markdown('<div class="section-header">üë§ Reporter Information</div>', unsafe_allow_html=True)
            col1, col2 = st.columns([1, 1], gap="large")
            
            with col1:
                reporter = st.text_input(
                    "Reporter",
                    placeholder="Enter your name",
                    help="This will be used for correspondence regarding your complaint",
                    key="reporter_name"
                )
                st.markdown('<span class="required-field">*Required</span>', unsafe_allow_html=True)
                
            with col2:
                schools = load_school_names()
                if schools:
                    school = st.selectbox(
                        "School/Institution",
                        schools,
                        index=0,
                        help="Select your school from the dropdown",
                        key="reporter_school"
                    )
                else:
                    school = st.text_input(
                        "School/Institution",
                        placeholder="Enter your school name",
                        help="Please type your school name manually",
                        key="reporter_school_manual"
                    )
                st.markdown('<span class="required-field">*Required</span>', unsafe_allow_html=True)
            
            st.markdown('<div style="margin: 1.5rem 0;"></div>', unsafe_allow_html=True)  # Spacer
            
            # Complaint Details Section
            st.markdown('<div class="section-header">üìã Complaint Details</div>', unsafe_allow_html=True)
            
            col3, col4 = st.columns([1, 1], gap="large")
            
            with col3:
                category = st.selectbox(
                    "Issue Category",
                    ["Login Issue", "Access Issue", "Content Issue", "Technical", "Other"],
                    help="Select the category that best describes your issue",
                    key="complaint_category"
                )
                st.markdown('<span class="required-field">*Required</span>', unsafe_allow_html=True)
                
            with col4:
                severity = st.selectbox(
                    "Priority Level",
                    ["High", "Medium", "Low"],
                    index=1,  # Default to Medium
                    help="High: Urgent issue affecting work\nMedium: Important but not urgent\nLow: Minor issue or suggestion",
                    key="complaint_severity"
                )
                st.markdown('<span class="required-field">*Required</span>', unsafe_allow_html=True)
            
            st.markdown('<div style="margin: 1rem 0;"></div>', unsafe_allow_html=True)  # Spacer
            
            # Description Section
            st.markdown('<div class="section-header">üìù Issue Description</div>', unsafe_allow_html=True)
            description = st.text_area(
                "Detailed Description",
                height=120,
                placeholder="Please provide a clear and detailed description of the issue you are experiencing.",
                help="The more details you provide, the better we can assist you",
                key="complaint_description"
            )
            st.markdown('<span class="required-field">*Required</span>', unsafe_allow_html=True)
            
            st.markdown('<div style="margin: 1.5rem 0;"></div>', unsafe_allow_html=True)  # Spacer
            
            # Attachment Section
            st.markdown('<div class="section-header">üìé Supporting Documents</div>', unsafe_allow_html=True)
            uploaded_file = st.file_uploader(
                "Upload Supporting Files (Optional)",
                type=["pdf", "jpg", "jpeg", "png", "docx", "xlsx"],
                help="You can attach screenshots, documents, or other files that help explain your issue",
                key="complaint_attachment"
            )
            
            # Submit button with professional styling
            st.markdown('<div style="margin: 2rem 0 1rem 0;"></div>', unsafe_allow_html=True)
            
            col_submit = st.columns([1, 2, 1])
            with col_submit[1]:
                submitted = st.form_submit_button(
                    "üöÄ Submit Complaint",
                    use_container_width=True,
                    type="primary"
                )
        
        st.markdown('</div>', unsafe_allow_html=True)  # Close form wrapper
        
        # Form submission logic
        if submitted:
            required_fields = {
                "Reporter Name": reporter, 
                "School": school, 
                "Category": category,
                "Severity": severity, 
                "Description": description
            }
            missing = [k for k, v in required_fields.items() if not str(v).strip()]
            
            if missing:
                st.error(f"‚ö†Ô∏è Please complete the following required fields: **{', '.join(missing)}**")
            else:
                try:
                    # Show processing message
                    with st.spinner("Processing your complaint..."):
                        file_link = upload_to_drive(uploaded_file) if uploaded_file else ""
                        row = [get_ist_timestamp(), school, reporter, category, severity,
                               description, "Open", file_link]
                        append_complaint_row(row)
                    
                    # Success message with better formatting
                    st.success("‚úÖ **Complaint Submitted Successfully!**")
                    st.info("üìß You will receive a confirmation email shortly with your complaint details and reference number.")

                    # Send emails
                    reporter_email = get_reporter_email(reporter)
                    if reporter_email:
                        body = f"""Dear {reporter},

Your complaint has been registered successfully.

Complaint Details:
‚Ä¢ School: {school}
‚Ä¢ Category: {category}
‚Ä¢ Priority: {severity}
‚Ä¢ Description: {description}
‚Ä¢ Attachment: {file_link if file_link else 'None'}

We will review your complaint and get back to you soon.

Best regards,
Customer Success Team
"""
                        send_email_with_attachments(reporter_email, "Complaint Registered - Confirmation", body)
                        send_email_with_attachments(ADMIN_EMAIL, f"New Complaint Submitted by {reporter}", body)
                        
                except Exception as e:
                    st.error(f"‚ùå **Submission Failed:** We encountered an error while processing your complaint. Please try again or contact support directly.\n\nTechnical details: {str(e)}")

    # Add some spacing after the form
    st.markdown('<div style="margin: 2rem 0;"></div>', unsafe_allow_html=True)

    st.markdown("---")

    # Recent complaints
    st.subheader("üìä Recent complaints")
    try:
        df_recent = fetch_recent_complaints(limit=50)
        if df_recent.empty:
            st.info("‚ÑπÔ∏è No complaints found yet.")
        else:
            if status_filter != "All" and "Status" in df_recent.columns:
                df_recent = df_recent[df_recent["Status"].astype(str).str.strip().str.lower() == status_filter.lower()]
            if df_recent.empty:
                st.info(f"‚ÑπÔ∏è No complaints with status '{status_filter}'.")
            else:
                if "Attachment" in df_recent.columns:
                    df_recent["Attachment"] = df_recent["Attachment"].apply(lambda x: f"[üìé View File]({x})" if x else "")
                if "Status" in df_recent.columns:
                    color_map = {"open": "üî¥ Open", "in progress": "üü† In Progress", "closed": "üü¢ Closed"}
                    df_recent["Status"] = df_recent["Status"].apply(lambda x: color_map.get(str(x).strip().lower(), x))
                st.dataframe(df_recent, use_container_width=True, hide_index=True)
    except Exception as e:
        st.error(f"‚ùå Could not load recent complaints. Details: {e}")

# ----------------------------
# PAGE 2: IMPLEMENTATION MONITORING (REBUILT KPIs + VISUALS)
# ----------------------------
if selected == "Implementation Monitoring":
    st.title("üìà Implementation Monitoring")

    df_impl = load_implementation_data()
    if df_impl.empty:
        st.info("‚ÑπÔ∏è No implementation data available.")
    else:
        # Normalize column names to ease lookups
        cols_map = {c: c for c in df_impl.columns}
        lower_cols = {c.lower(): c for c in df_impl.columns}

        # helper to get column by list of possible keywords
        def col_for(*keywords):
            for kw in keywords:
                for c in df_impl.columns:
                    if kw.lower() in c.lower():
                        return c
            return None

        # find key columns robustly
        school_col = col_for("school name", "school")
        zone_col = col_for("zone")
        welcome_col = col_for("welcome mail", "welcome", "welcome mail status")
        induction_col = col_for("induction training", "induction")
        capacity_col = col_for("capacity building", "capacity")
        proflearn_col = col_for("professional learning", "professional learning", "professional")
        refresher_col = col_for("refresher", "refresher training")
        contract_end_col = col_for("contract end", "contract end date", "contract end date")
        retention_col = col_for("retention probability", "retention prob", "retention probablity", "retention")

        # Total schools unique
        total_schools = df_impl[school_col].nunique() if school_col else 0

        # Onboarded: use welcome / BOAT access start / login id heuristics
        onboarded = 0
        if welcome_col and welcome_col in df_impl.columns:
            onboarded = df_impl[df_impl[welcome_col].astype(str).str.strip().str.lower().isin(["sent", "yes", "y", "done", "completed"])][school_col].nunique() if school_col else 0
        else:
            # fallback: presence of BOAT access start date or Login ID
            boat_col = col_for("boat access start", "boat access", "id creation date on BOAT", "boat id")
            login_col = col_for("login id", "login")
            onboarded = 0
            if boat_col and boat_col in df_impl.columns:
                onboarded = df_impl[df_impl[boat_col].astype(str).str.strip().astype(bool)][school_col].nunique() if school_col else 0
            elif login_col and login_col in df_impl.columns:
                onboarded = df_impl[df_impl[login_col].astype(str).str.strip().astype(bool)][school_col].nunique() if school_col else 0

        # milestone completed counts (per-column)
        def count_completed(colname):
            if not colname or colname not in df_impl.columns:
                return 0
            return df_impl[df_impl[colname].apply(is_completed_value)][school_col].nunique() if school_col else 0

        induction_done = count_completed(induction_col)
        capacity_done = count_completed(capacity_col)
        proflearn_done = count_completed(proflearn_col)
        refresher_done = count_completed(refresher_col) if refresher_col else 0

        # Build per-school completion % using available milestones
        milestones = []
        for c in [induction_col, capacity_col, proflearn_col, refresher_col]:
            if c and c in df_impl.columns:
                milestones.append(c)
        # If no milestones found, fallback to 'Training Status' column if present
        training_status_col = col_for("training status")
        if not milestones and training_status_col:
            milestones = [training_status_col]

        # compute completion per school (0..1)
        perc_df = pd.DataFrame()
        if school_col:
            schools = df_impl[school_col].dropna().unique()
            rows = []
            for s in schools:
                sub = df_impl[df_impl[school_col] == s]
                # for a school could be multiple rows; treat any completed in any row as completed
                completed_count = 0
                total_count = 0
                for m in milestones:
                    total_count += 1
                    # consider completed if any row for that school has completed for that milestone
                    if sub[m].apply(is_completed_value).any():
                        completed_count += 1
                pct = (completed_count / total_count) * 100 if total_count else 0
                rows.append({"school": s, "completed_pct": pct})
            perc_df = pd.DataFrame(rows)
        avg_completion_pct = round(perc_df["completed_pct"].mean(), 1) if not perc_df.empty else 0

        # Retention probability average (if present)
        avg_retention = None
        if retention_col and retention_col in df_impl.columns:
            # try converting to numeric (strip % if present)
            def parse_ret(x):
                try:
                    s = str(x).replace("%", "").strip()
                    return float(s) if s not in ["", "na", "n/a"] else None
                except:
                    return None
            ret_series = df_impl[retention_col].apply(parse_ret).dropna()
            avg_retention = round(ret_series.mean(), 1) if not ret_series.empty else None

        # Pending = total - induction_done (or some other definition)
        # We'll present pending for induction as example:
        pending_induction = total_schools - induction_done if total_schools else 0

        # Display KPIs
        k1, k2, k3, k4, k5 = st.columns([1.2,1,1,1,1])
        k1.metric("üè´ Total Schools", total_schools)
        k2.metric("üìß Onboarded", onboarded)
        k3.metric("üéì Induction Completed", induction_done)
        k4.metric("üèã Capacity Completed", capacity_done)
        k5.metric("üìö Professional Learning", proflearn_done)
        st.markdown("")  # spacing
        k6, k7 = st.columns([1,1])
        k6.metric("üìà Avg Implementation %", f"{avg_completion_pct}%")
        k7.metric("üîÅ Avg Retention Prob.", f"{avg_retention}%" if avg_retention is not None else "N/A")

        st.markdown("---")

        # Funnel visualization
        funnel_stages = []
        funnel_names = []
        if induction_col and induction_col in df_impl.columns:
            funnel_stages.append(induction_done); funnel_names.append("Induction")
        if capacity_col and capacity_col in df_impl.columns:
            funnel_stages.append(capacity_done); funnel_names.append("Capacity")
        if proflearn_col and proflearn_col in df_impl.columns:
            funnel_stages.append(proflearn_done); funnel_names.append("Professional Learning")
        if refresher_col and refresher_col in df_impl.columns:
            funnel_stages.append(refresher_done); funnel_names.append("Refresher")

        if funnel_stages:
            funnel_df = pd.DataFrame({"stage": funnel_names, "count": funnel_stages})
            fig_funnel = px.bar(funnel_df, x="stage", y="count", text="count", title="Implementation Funnel (counts)")
            st.plotly_chart(fig_funnel, use_container_width=True)

        # Zone-level implementation %
        if zone_col and zone_col in df_impl.columns and milestones:
            # compute zone-wise % trained (based on milestones average per school in zone)
            zone_grouped = df_impl.groupby(zone_col).apply(
                lambda g: pd.Series({
                    "schools": g[school_col].nunique() if school_col else 0,
                    "pct_done": (g.apply(lambda r: sum(is_completed_value(r[m]) for m in milestones) / len(milestones) if len(milestones) else 0, axis=1).sum() / (g.shape[0])) * 100 if g.shape[0] else 0
                })
            ).reset_index()
            # The above calculation can be noisy due to duplicates; instead compute per-school within zone:
            zone_school = df_impl.groupby([zone_col, school_col]).first().reset_index()
            def school_pct(row):
                done = sum(is_completed_value(row[m]) for m in milestones)
                return (done / len(milestones)) * 100 if len(milestones) else 0
            zone_school["completed_pct"] = zone_school.apply(school_pct, axis=1)
            zone_stats = zone_school.groupby(zone_col)["completed_pct"].mean().reset_index(name="avg_completed_pct")
            fig_zone = px.bar(zone_stats, x=zone_col, y="avg_completed_pct", text="avg_completed_pct",
                              title="Avg Implementation % by Zone")
            st.plotly_chart(fig_zone, use_container_width=True)

        # Upcoming contract expiries (next 90 days)
        if contract_end_col and contract_end_col in df_impl.columns:
            # try parse dates
            def parse_date(x):
                for fmt in ("%Y-%m-%d", "%d-%m-%Y", "%d/%m/%Y", "%m/%d/%Y"):
                    try:
                        return pd.to_datetime(x, format=fmt)
                    except:
                        pass
                try:
                    return pd.to_datetime(x, errors="coerce")
                except:
                    return pd.NaT
            df_impl["_contract_end_dt"] = df_impl[contract_end_col].apply(parse_date)
            cutoff = pd.Timestamp.now() + pd.Timedelta(days=90)
            soon = df_impl[(df_impl["_contract_end_dt"].notna()) & (df_impl["_contract_end_dt"] <= cutoff)].copy()
            if not soon.empty:
                soon_table = soon[[school_col, zone_col, contract_end_col, "_contract_end_dt"]].rename(columns={school_col:"School", zone_col:"Zone", contract_end_col:"Contract End Date"})
                soon_table["Contract End Date"] = pd.to_datetime(soon_table["Contract End Date"], errors="coerce").dt.date
                st.markdown("### ‚ö†Ô∏è Contracts ending in next 90 days")
                st.dataframe(soon_table.sort_values("Contract End Date"), use_container_width=True)
            else:
                st.info("No contracts ending in the next 90 days (based on Contract End Date column).")
        else:
            st.info("Contract end column not found in implementation sheet (searching for 'Contract End date').")

        st.markdown("---")

        # Zone-level table with counts per milestone
        if zone_col and zone_col in df_impl.columns:
            agg = {}
            # For each milestone, compute number completed per zone
            for m in milestones:
                df_impl[f"__{m}_completed"] = df_impl[m].apply(is_completed_value)
            group_cols = [zone_col]
            agg_df = df_impl.groupby(zone_col).agg(
                total_schools=(school_col, lambda s: s.nunique() if school_col else 0),
                induction_completed=(induction_col, lambda s: (s.apply(is_completed_value).sum()) if induction_col else 0),
            ).reset_index()
            # Build dynamic columns
            zone_table = df_impl.groupby(zone_col).apply(lambda g: pd.Series({
                "Total Schools": g[school_col].nunique() if school_col else 0,
                **{f"{m} Completed": g[m].apply(is_completed_value).sum() for m in milestones}
            })).reset_index()
            st.markdown("### Zone / Milestone summary")
            st.dataframe(zone_table, use_container_width=True)

        st.caption("Tip: if numbers look off, ensure 'School Name' is filled consistently (duplicates across rows will be aggregated).")
